{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfd69c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T01:53:29.514778Z",
     "start_time": "2023-08-31T01:53:29.461991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片宽度存在例外500\n",
      "图片高度存在例外334\n",
      "普遍宽度: 500 像素, 普遍高度: 334 像素\n"
     ]
    }
   ],
   "source": [
    "#查看一下原文件下的图片大小均为几何\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 指定包含图片的文件夹路径\n",
    "folder_path = r\"\"E:\\Code\\GAN\\generated_images\"\n",
    "# folder_path = r\"E:\\Code\\GAN\\data\\Plaster_side\"\n",
    "\n",
    "# 获取文件夹中所有的文件\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# 遍历文件夹中的每个文件\n",
    "for file_name in file_list:\n",
    "    # 确保文件是tif格式的图片\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # 打开图片\n",
    "        img = Image.open(file_path)\n",
    "\n",
    "        # 获取图片的大小\n",
    "        width, height = img.size\n",
    "        if width != 548:\n",
    "            print('图片宽度存在例外{}'.format(width))\n",
    "        if height != 822:\n",
    "            print('图片高度存在例外{}'.format(height)) \n",
    "\n",
    "        # 关闭图片\n",
    "        img.close()\n",
    "                       \n",
    "# 打印图片的大小\n",
    "print(f\"普遍宽度: {width} 像素, 普遍高度: {height} 像素\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e56669d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:44.914564Z",
     "start_time": "2023-08-30T01:09:44.900611Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_fid import fid_score\n",
    "import cv2\n",
    "import optuna\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be47267b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:44.930510Z",
     "start_time": "2023-08-30T01:09:44.916557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置GPU设备（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4551aa37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:44.946457Z",
     "start_time": "2023-08-30T01:09:44.932504Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),  # 调整图片大小\n",
    "    transforms.ToTensor(),         # 转换为张量\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0872f7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:44.962404Z",
     "start_time": "2023-08-30T01:09:44.949447Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据加载和预处理\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_root, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.image_files = [f for f in os.listdir(data_root) if f.lower().endswith(\".tif\")]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.data_root, self.image_files[idx])\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # 返回数据（不返回标签）\n",
    "            return image\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_name}: {e}\")\n",
    "            # 返回一个空tensor，表示数据加载失败\n",
    "            return torch.empty((3, 64, 64))\n",
    "\n",
    "def get_data_loader(data_root, batch_size):\n",
    "    transform = transforms.Compose([\n",
    "#         transforms.Resize(224),\n",
    "#         transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    dataset = CustomDataset(data_root, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b1fddac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:44.994297Z",
     "start_time": "2023-08-30T01:09:44.980343Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载自定义数据集\n",
    "custom_dataset = CustomDataset(data_root=\"E:/Code/GAN/data/Plaster_side\", transform=transform)\n",
    "# DataLoader用于批量处理\n",
    "dataloader = DataLoader(custom_dataset, batch_size=64, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356d24c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.010243Z",
     "start_time": "2023-08-30T01:09:44.996290Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义生成器\n",
    "# 可以根据需要调整ngf、nz、nc、ndf和其他超参数来满足你的需求。这些参数控制着模型的深度和宽度，可以影响生成图片的质量。\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngf=64, nz=100, nc=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7821b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.026191Z",
     "start_time": "2023-08-30T01:09:45.012237Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义判别器\n",
    "# 可以根据需要调整ngf、nz、nc、ndf和其他超参数来满足你的需求。这些参数控制着模型的深度和宽度，可以影响生成图片的质量。\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ndf=64, nc=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0af79bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.042137Z",
     "start_time": "2023-08-30T01:09:45.029181Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建SummaryWriter来记录损失到TensorBoard\n",
    "writer = SummaryWriter(log_dir=f\"runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "131df804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.057088Z",
     "start_time": "2023-08-30T01:09:45.044131Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在这里你可以计算你的优化指标，如生成图片的质量等\n",
    "real_images_folder_path = \"E:/Code/GAN/data/Plaster_side\"\n",
    "\n",
    "def compute_fid(generator, num_samples=100, device='cuda'):\n",
    "    # 创建临时目录用于保存生成的图片\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "    # 生成num_samples张图片并保存到临时目录\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            noise = torch.randn(1, 100, 1, 1).to(device)\n",
    "            fake_image = generator(noise)\n",
    "            fake_image = fake_image[0].cpu().numpy()\n",
    "            fake_image = (fake_image + 1.0) / 2.0  # 将像素值范围从[-1, 1]转换到[0, 1]\n",
    "            fake_image = (fake_image * 255).astype(np.uint8)  # 转换为整数类型\n",
    "            fake_image = np.transpose(fake_image, (1, 2, 0))  # 将通道维度移到最后\n",
    "            image_filename = os.path.join(temp_dir, f'fake_image_{i}.png')\n",
    "            cv2.imwrite(image_filename, fake_image)\n",
    "\n",
    "    # 计算FID指标\n",
    "    fid = fid_score.calculate_fid_given_paths(\n",
    "        [str(real_images_folder_path), temp_dir],  # 真实图片文件夹和生成图片文件夹的路径\n",
    "        batch_size=50,\n",
    "        device=device,\n",
    "        dims=2048  # 这个值应该与 Inception V3 模型的输出维度匹配\n",
    "    )\n",
    "\n",
    "    # 删除临时生成的图片\n",
    "    for i in range(num_samples):\n",
    "        image_filename = os.path.join(temp_dir, f'fake_image_{i}.png')\n",
    "        os.remove(image_filename)\n",
    "    os.rmdir(temp_dir)  # 删除临时目录\n",
    "\n",
    "    return fid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c164474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.072038Z",
     "start_time": "2023-08-30T01:09:45.060077Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义超参数搜索空间\n",
    "def objective(trial):\n",
    "    # 定义超参数搜索范围\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    ngf = trial.suggest_int('ngf', 32, 256)\n",
    "    ndf = trial.suggest_int('ndf', 32, 256)\n",
    "\n",
    "    # 创建生成器和判别器\n",
    "    generator = Generator(ngf=ngf).to(device)\n",
    "    discriminator = Discriminator(ndf=ndf).to(device)\n",
    "\n",
    "    # 定义优化器\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "    # 定义损失函数\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # 学习率调度器，这里使用 StepLR 调度器作为示例\n",
    "    scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.1)\n",
    "    scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=30, gamma=0.1)\n",
    "\n",
    "    # 训练模型\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, real_images in enumerate(dataloader):\n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            # 训练判别器\n",
    "            optimizer_D.zero_grad()\n",
    "            real_outputs = discriminator(real_images)\n",
    "\n",
    "            # 创建与 real_outputs 相同维度的 real_labels\n",
    "            real_labels = torch.ones_like(real_outputs).to(device)\n",
    "\n",
    "            real_loss = criterion(real_outputs, real_labels)\n",
    "            real_loss.backward()\n",
    "\n",
    "            noise = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_outputs = discriminator(fake_images.detach())\n",
    "\n",
    "            # 创建与 fake_outputs 相同维度的 fake_labels\n",
    "            fake_labels = torch.zeros_like(fake_outputs).to(device)\n",
    "\n",
    "            fake_loss = criterion(fake_outputs, fake_labels)\n",
    "            fake_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # 训练生成器\n",
    "            optimizer_G.zero_grad()\n",
    "            fake_outputs = discriminator(fake_images)\n",
    "\n",
    "            # 创建与 fake_outputs 相同维度的 real_labels（因为生成器希望生成的图像被判别为真实的）\n",
    "            real_labels = torch.ones_like(fake_outputs).to(device)\n",
    "\n",
    "            g_loss = criterion(fake_outputs, real_labels)\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "#              # 记录损失到TensorBoard\n",
    "#             global_step = epoch * len(dataloader) + batch_idx\n",
    "#             writer.add_scalar('Loss/Real Loss', real_loss.item(), global_step)\n",
    "#             writer.add_scalar('Loss/Fake Loss', fake_loss.item(), global_step)\n",
    "#             writer.add_scalar('Loss/Generator Loss', g_loss.item(), global_step)\n",
    "    \n",
    "        # 学习率调度器更新学习率\n",
    "        scheduler_G.step()\n",
    "        scheduler_D.step()\n",
    "        \n",
    "    # 计算你的优化指标，如生成图片的质量等\n",
    "    fid = compute_fid(generator, num_samples=100, device=device)\n",
    "\n",
    "    return fid  # 返回FID作为优化指标\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31ab0328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:09:45.087984Z",
     "start_time": "2023-08-30T01:09:45.074030Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-30 09:09:45,076] A new study created in memory with name: no-name-c69f4712-94a7-49d3-8e40-5af568e6fd9b\n"
     ]
    }
   ],
   "source": [
    "# 创建Optuna study对象\n",
    "study = optuna.create_study(direction='minimize')  # 我们将FID视为需要最小化的指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2dbaf1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.323517Z",
     "start_time": "2023-08-30T01:09:45.091970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_9148\\4116395331.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "[I 2023-08-30 09:10:28,499] Trial 0 finished with value: 435.47806486800806 and parameters: {'lr': 0.0009269545783490616, 'batch_size': 64, 'ngf': 187, 'ndf': 141}. Best is trial 0 with value: 435.47806486800806.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "[I 2023-08-30 09:11:15,292] Trial 1 finished with value: 410.89280127008675 and parameters: {'lr': 0.00860859467689019, 'batch_size': 64, 'ngf': 69, 'ndf': 244}. Best is trial 1 with value: 410.89280127008675.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "[I 2023-08-30 09:12:07,095] Trial 2 finished with value: 462.5181705845664 and parameters: {'lr': 0.00030930754957256106, 'batch_size': 32, 'ngf': 211, 'ndf': 233}. Best is trial 1 with value: 410.89280127008675.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "[I 2023-08-30 09:12:49,792] Trial 3 finished with value: 424.29945795774074 and parameters: {'lr': 0.002112435004563004, 'batch_size': 128, 'ngf': 112, 'ndf': 216}. Best is trial 1 with value: 410.89280127008675.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.44it/s]\n",
      "[I 2023-08-30 09:13:24,134] Trial 4 finished with value: 522.6626101615816 and parameters: {'lr': 0.00022296927715597493, 'batch_size': 64, 'ngf': 192, 'ndf': 106}. Best is trial 1 with value: 410.89280127008675.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.46it/s]\n",
      "[I 2023-08-30 09:14:05,802] Trial 5 finished with value: 474.8604342931317 and parameters: {'lr': 0.00029150347998055235, 'batch_size': 128, 'ngf': 129, 'ndf': 196}. Best is trial 1 with value: 410.89280127008675.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.37it/s]\n",
      "[I 2023-08-30 09:14:52,593] Trial 6 finished with value: 382.85316126593574 and parameters: {'lr': 0.0013117504668070051, 'batch_size': 64, 'ngf': 56, 'ndf': 244}. Best is trial 6 with value: 382.85316126593574.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "[I 2023-08-30 09:15:27,027] Trial 7 finished with value: 407.96767352602876 and parameters: {'lr': 0.0011230152150859063, 'batch_size': 128, 'ngf': 37, 'ndf': 98}. Best is trial 6 with value: 382.85316126593574.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.42it/s]\n",
      "[I 2023-08-30 09:15:59,477] Trial 8 finished with value: 408.9052451044661 and parameters: {'lr': 0.004390354213234739, 'batch_size': 32, 'ngf': 186, 'ndf': 34}. Best is trial 6 with value: 382.85316126593574.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.43it/s]\n",
      "[I 2023-08-30 09:16:35,319] Trial 9 finished with value: 496.50706317953586 and parameters: {'lr': 1.8515791300005692e-05, 'batch_size': 128, 'ngf': 139, 'ndf': 136}. Best is trial 6 with value: 382.85316126593574.\n"
     ]
    }
   ],
   "source": [
    "# 开始超参数优化\n",
    "study.optimize(objective, n_trials=10)  # 你可以调整n_trials来控制搜索次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5b087c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.338466Z",
     "start_time": "2023-08-30T01:16:35.324513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Best FID: 382.85316126593574\n",
      "Best Params: \n",
      "lr: 0.0013117504668070051\n",
      "batch_size: 64\n",
      "ngf: 56\n",
      "ndf: 244\n"
     ]
    }
   ],
   "source": [
    "# 输出最佳超参数和最佳指标值,optuna只是寻找出了最佳参数组合，而并没有对模型进行训练\n",
    "print(\"Best trial:\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best FID: {best_trial.value}\")\n",
    "print(\"Best Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "273fe522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.524843Z",
     "start_time": "2023-08-30T01:16:35.339464Z"
    }
   },
   "outputs": [],
   "source": [
    "# 创建生成器和判别器模型（使用最佳超参数）\n",
    "best_ngf = best_trial.params['ngf']\n",
    "best_ndf = best_trial.params['ndf']\n",
    "best_lr = best_trial.params['lr']\n",
    "# best_lr = 0.5\n",
    "#使用手动调整，optuna计算出来的学习率可能偏小\n",
    "\n",
    "# 创建生成器和判别器模型（使用最佳超参数）\n",
    "generator = Generator(ngf=best_ngf).to(device)\n",
    "discriminator = Discriminator(ndf=best_ndf).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d0ac247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.540790Z",
     "start_time": "2023-08-30T01:16:35.525841Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义优化器和损失函数\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=best_lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=best_lr, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0237220",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.556736Z",
     "start_time": "2023-08-30T01:16:35.541786Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学习率调度器，这里使用 StepLR 调度器作为示例\n",
    "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=30, gamma=0.1)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe529b7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T01:16:35.571687Z",
     "start_time": "2023-08-30T01:16:35.557733Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重新加载数据集\n",
    "data_loader = get_data_loader(data_root=\"E:/Code/GAN/data/Plaster_side\", batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb216613",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T15:39:23.689418Z",
     "start_time": "2023-08-30T01:16:35.572684Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重新训练模型\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, real_images in enumerate(dataloader):\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # 训练判别器\n",
    "        optimizer_D.zero_grad()\n",
    "        real_outputs = discriminator(real_images)\n",
    "\n",
    "        # 创建与 real_outputs 相同维度的 real_labels\n",
    "        real_labels = torch.ones_like(real_outputs).to(device)\n",
    "\n",
    "        real_loss = criterion(real_outputs, real_labels)\n",
    "        real_loss.backward()\n",
    "\n",
    "        noise = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_outputs = discriminator(fake_images.detach())\n",
    "\n",
    "        # 创建与 fake_outputs 相同维度的 fake_labels\n",
    "        fake_labels = torch.zeros_like(fake_outputs).to(device)\n",
    "\n",
    "        fake_loss = criterion(fake_outputs, fake_labels)\n",
    "        fake_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 训练生成器\n",
    "        optimizer_G.zero_grad()\n",
    "        fake_outputs = discriminator(fake_images)\n",
    "\n",
    "        # 创建与 fake_outputs 相同维度的 real_labels（因为生成器希望生成的图像被判别为真实的）\n",
    "        real_labels = torch.ones_like(fake_outputs).to(device)\n",
    "\n",
    "        g_loss = criterion(fake_outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "    # 学习率调度器更新学习率\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "\n",
    "    # 记录损失到TensorBoard\n",
    "    global_step = epoch * len(dataloader) + batch_idx\n",
    "    writer.add_scalar('Loss/Real Loss', real_loss.item(), global_step)\n",
    "    writer.add_scalar('Loss/Fake Loss', fake_loss.item(), global_step)\n",
    "    writer.add_scalar('Loss/Generator Loss', g_loss.item(), global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2b741b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T15:39:23.736261Z",
     "start_time": "2023-08-30T15:39:23.696394Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存最佳模型权重\n",
    "torch.save(generator.state_dict(), \"best_generator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5af87ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T15:39:23.800048Z",
     "start_time": "2023-08-30T15:39:23.738255Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定保存图像的目录\n",
    "output_dir = 'generated_images'\n",
    "\n",
    "# 如果目录不存在，创建它\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "# 使用最佳模型生成图像\n",
    "\n",
    "generator.load_state_dict(torch.load(\"best_generator.pth\"))\n",
    "generator.eval()  # 设置为评估模式\n",
    "with torch.no_grad():\n",
    "    num_samples = 10\n",
    "    for i in range(num_samples):\n",
    "        noise = torch.randn(1, 100, 1, 1).to(device)\n",
    "        fake_image = generator(noise)\n",
    "        # 将生成的图片保存到指定目录\n",
    "        save_image(fake_image, os.path.join(output_dir, f'generated_image_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "318ba211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T15:39:23.814998Z",
     "start_time": "2023-08-30T15:39:23.801045Z"
    }
   },
   "outputs": [],
   "source": [
    "# 关闭SummaryWriter\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2531f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-31T13:10:33.985977Z",
     "start_time": "2023-08-31T13:10:33.966044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30316), started 3 days, 11:52:25 ago. (Use '!kill 30316' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b7247bb4fd3391cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b7247bb4fd3391cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'runs'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
